[project]
project_name            = "llm-cpu"

[model]
model_bucket_prefix     = "model-bucket"
model_hugging_face_name = "TheBloke/Llama-2-7b-Chat-GGUF"
model_full_name         = "llama-2-7b-chat.Q4_K_M.gguf"
; model_hugging_face_name = "TheBloke/zephyr-7B-beta-GGUF"
; model_full_name         = "zephyr-7b-beta.Q4_K_M.gguf"

[image]
image_repository_name   = "model-image-repository"
platform                = "ARM"
image_tag               = "arm-latest"
; platform                = "AMD"
; image_tag               = "amd-latest"

[inference]
sagemaker_role_name     = "sagemaker-execution-role"
sagemaker_model_name    = "llama-2-7b-chat-arm"
instance_type           = "ml.c7g.2xlarge"
; instance_type           = "ml.g5.xlarge"
