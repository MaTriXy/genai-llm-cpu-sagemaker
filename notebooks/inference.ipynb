{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we define the functionality to interact with endpoint. \n",
    "we use different function for handling streaming response as the output format is different.\n",
    "define \"endpoint_name\" variable below based on the cloudformation stack output.\n",
    "\"\"\"\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime', region_name='us-east-1')\n",
    "endpoint_name='llmcpp-llama-2-7b-chat-llama-2-7b-chat-arm-Endpoint'\n",
    "\n",
    "def invoke_sagemaker_endpoint(endpoint_name, llama_args):\n",
    "    payload = {\n",
    "        'inference': True,\n",
    "        'configure': False,\n",
    "        'args': llama_args\n",
    "    }\n",
    "    response = sagemaker_runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=json.dumps(llama_args),\n",
    "        ContentType='application/json',\n",
    "    )\n",
    "    response_body = json.loads(response['Body'].read().decode())\n",
    "    return response_body\n",
    "\n",
    "def invoke_sagemaker_streaming_endpoint(endpoint_name, payload):\n",
    "    response = sagemaker_runtime.invoke_endpoint_with_response_stream(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=json.dumps(payload),\n",
    "        ContentType='application/json',\n",
    "    )    \n",
    "    event_stream = response['Body']\n",
    "    for line in event_stream:\n",
    "        itm = line['PayloadPart']['Bytes'][6:]\n",
    "        try:\n",
    "            res = json.loads(itm, strict=False )\n",
    "            print(res[\"choices\"][0][\"text\"], end='')\n",
    "        except:\n",
    "            #non-valid json, e.g. empty token \n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Non-streaming inference example.   \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "llama_args = {\n",
    "    \"prompt\": \"What are top 10 destinations to visit in Europe?\",\n",
    "    \"max_tokens\": 128,\n",
    "    \"temperature\": 0.1,\n",
    "    \"repeat_penalty\":1.5,\n",
    "    \"frequency_penalty\":1.1,\n",
    "    \"top_p\": 0.5\n",
    "}\n",
    "\n",
    "inference = invoke_sagemaker_endpoint(endpoint_name,llama_args)\n",
    "inference['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Streaming inference example\n",
    "to enable streaming mode, set stream=True\n",
    "\"\"\"\n",
    "\n",
    "llama_args = {\n",
    "    \"prompt\": \"What are top 10 destinations to visit in Europe?\",\n",
    "    \"max_tokens\": 300,\n",
    "    \"temperature\": 0.1,\n",
    "    \"repeat_penalty\":1.5,\n",
    "    \"frequency_penalty\":1.1,\n",
    "    \"top_p\": 0.5,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "invoke_sagemaker_streaming_endpoint(endpoint_name,llama_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
